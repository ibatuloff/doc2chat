{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import llama_index\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "bot = telebot.TeleBot('7635204662:AAE4WQywEaR3bXwtVZL33sQHHIiq4UERz-c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"/app/data\")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OptimumEmbedding(folder_name=\"/app/models/all-mpnet-base-v2_onnx\")\n",
    "Settings.llm = Ollama(model=\"qwen25_7b\", request_timeout=180.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuning a Language Model (LLM) involves adapting it to perform specific tasks or domains more effectively. The process typically includes several key steps:\n",
      "\n",
      "1. **Foundational Insights**: Understanding the basics of LLMs, their pre-training phases, and how they operate is crucial. This knowledge helps in identifying areas where fine-tuning can improve model performance.\n",
      "\n",
      "2. **Definition of Fine-Tuning**: Fine-tuning refers to the process of adapting a pre-trained model on a specific dataset for a particular task or domain. It contrasts with pre-training, which focuses on learning general language patterns and features from large datasets.\n",
      "\n",
      "3. **Structured Pipeline**: A fine-tuning pipeline usually consists of several stages:\n",
      "   - **Model Initialization**: Starting with a pre-trained model that has learned general language patterns.\n",
      "   - **Hyperparameter Definition**: Setting the parameters required for training, such as batch size, learning rate, and number of epochs.\n",
      "   - **Fine-Tuning Techniques**: Implementing various fine-tuning strategies. For example:\n",
      "     - **Parameter-Efficient Fine-Tuning (PEFT)**: This approach aims to minimize the number of trainable parameters while still improving model performance.\n",
      "     - **Retrieval-Augmented Generation (RAG)**: Combining retrieval and generation techniques where models retrieve relevant information from a knowledge base before generating responses.\n",
      "\n",
      "4. **Practical Implementation**: Practical steps involve setting up the fine-tuning environment, selecting appropriate data for training, defining loss functions, and optimizing hyperparameters to achieve the best performance.\n",
      "\n",
      "5. **Evaluation Methods**: After fine-tuning, evaluating the model's performance using relevant metrics is essential. This helps in understanding how well the model has adapted to the specific task or domain.\n",
      "\n",
      "6. **Deployment Challenges**: Deploying a fine-tuned LLM involves addressing challenges such as computational resources, scalability, and ensuring the model remains up-to-date with new data and trends.\n",
      "\n",
      "By following these structured steps and leveraging advanced techniques like PEFT and RAG, one can effectively fine-tune an LLM for specific applications or domains. This process ensures that the model is better aligned with the requirements of targeted tasks, enhancing its performance and utility in various contexts such as Q&A systems, customer support automation, and summarization tasks. --------------------\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How can one fine-tune an LLM model?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
